{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "# Feeling Fine \n",
    "\n",
    "## Data pre-processing \n",
    "We first need to define some functions to pre process the data. This involves converting the audio file into something the computer can actually understand (numerical values). We are going to use the librosa library and it has some predefined extraction functions. \n",
    "\n",
    "We can extract the following information\n",
    "<img src=\"https://i.ibb.co/sbmCxfK/Screenshot-2020-11-30-at-13-54-26.png\" alt=\"Table of function\" width=\"600\"/>\n",
    "\n",
    "So, according to my research:\n",
    "* Chroma : relates to the 12 different pitches, we will be focused with the short term fourier transformation of the sound files. <img src=\"https://upload.wikimedia.org/wikipedia/commons/2/25/ChromaFeatureCmajorScaleScoreAudioColor.png\" alt=\"(Image of a the 12 different pitches)\" width=\"300\"/>\n",
    "* Melspectogram : This relates to different Mel scale and Spectrogram (Check notebook on more info)\n",
    "    * Mel scale : The mel scale is the result of non-linear transformations on frequencies to make it easier to plot and record the distance between frequencies\n",
    "    * Spectrograms : This is the way we plot audio, y axis is hertz, x axis is time, and there is a color spectrum, which ussually represents the decibles. \n",
    "* Mel Frequency Cepstral Co-efficients (MFCC) : A feature of sound (similar to edges in photos) / the log of the magnitude of the fourier transformation of sound waves ... \n",
    "* Spectral Centroid : The center of mass of the spectrum (also considered the brightness of the sound),\n",
    "* Spectral Bandwidth : the difference between the max and the min of the spectrum (max change in frequency),\n",
    "* Spectral Contrast : The differences between the peaks and the valleys in a spectrum, multiple andwidths calculated,\n",
    "* Roll-Off Frequency : The freqency at which the filter begins to cut off (not sure either)\n",
    "\n",
    "\n",
    "Okay, now we've gone into what we can extract from the sound waves in a bit more detail I'll briefly explain the thought process behind the selection I will make. I'm deciding to use Chroma since it measures the pitch. I'll use MFCC because it's a feature of sound that the model will be able to use well, I'll also include the spectral centroid, spectral Bandwidth, spectral contrast to try and mimic the variation in frequency based on the idea people have more voice cracks depending on their emotions (although though i am aware this might cause some over fitting in the model). I'll also include the melspectogram and finally I will also include the roll-off frequency as well under the assumption that even if I start the sentence with a lot of energy my emotions determine how fast i speak, the speed of my language determines my frequency (talking slower ussually gives out a lower sound), and the roll-off frequency might help determine this (once again might be over fitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa                                             # Audio analyser  \n",
    "import soundfile                                           # Read the audio files\n",
    "import os, glob, pickle                                    # Deal with files  \n",
    "import numpy as np                                         # Numpy used to manipulate dataframes\n",
    "from sklearn.model_selection import train_test_split       # For testing and training the model \n",
    "from sklearn.neural_network import MLPClassifier           # The ANN model  \n",
    "from sklearn.metrics import accuracy_score                 # used to test the accuracy of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "The function we are going to define takes in a file name, and flags (which parameters to include in extraction), and then returns a data structure which contains the mean of the extracted information. \n",
    "\n",
    "Flag names :\n",
    "* chroma - Chroma Short Term Fourier Transformation (Pitch)\n",
    "* mfcc - Mel Frequency Cepstral Co-Efficients\n",
    "* mel - Melspectrogram\n",
    "* spec_centroid - Spectral Centroid \n",
    "* spec_bandwidth - Spectral Bandwidth \n",
    "* spec_contrast - Spectral Contrast \n",
    "* roll_off - Roll-Off Frequency \n",
    "\n",
    "This function goes though each flag and then returns the mean value of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Extracting features \n",
    "Params : file_name (str), chroma (bool), mfcc (bool), mel (bool), spec_centroid (bool), spec_bandwidth (bool)\n",
    "           spec_contrast (bool), roll_off (bool) \n",
    "'''\n",
    "def extract_feature(file_name, chroma, mfcc, mel, spec_centroid, spec_bandwidth, spec_contrast, roll_off):\n",
    "    with soundfile.SoundFile(file_name) as sound_file:\n",
    "        raw_audio = sound_file.read(dtype=\"float32\") \n",
    "        sample_rate = sound_file.samplerate         \n",
    "        extracted_features = np.array([])\n",
    "        stft = np.abs(librosa.stft(raw_audio))\n",
    "        if chroma:\n",
    "            chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "            extracted_features = np.hstack((extracted_features, chroma))\n",
    "        if mfcc:\n",
    "            mfccs=np.mean(librosa.feature.mfcc(y=raw_audio, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
    "            extracted_features = np.hstack((extracted_features, mfccs))\n",
    "        if mel:\n",
    "            mel = np.mean(librosa.feature.melspectrogram(raw_audio, sr=sample_rate).T,axis=0)\n",
    "            extracted_features = np.hstack((extracted_features, mel))\n",
    "        if spec_centroid:\n",
    "            spec_centroid = np.mean(librosa.feature.spectral_centroid(y=raw_audio, sr=sample_rate).T,axis=0)\n",
    "            extracted_features = np.hstack((extracted_features, spec_centroid))\n",
    "        if spec_bandwidth:\n",
    "            spec_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=raw_audio, sr=sample_rate).T,axis=0)\n",
    "            extracted_features = np.hstack((extracted_features, spec_bandwidth))\n",
    "        if spec_contrast:\n",
    "            spec_contrast = np.mean(librosa.feature.spectral_contrast(y=raw_audio, sr=sample_rate).T,axis=0)\n",
    "            extracted_features = np.hstack((extracted_features, spec_contrast))\n",
    "        if roll_off:\n",
    "            roll_off = np.mean(librosa.feature.spectral_rolloff(y=raw_audio, sr=sample_rate).T,axis=0)\n",
    "            extracted_features = np.hstack((extracted_features, roll_off))\n",
    "    return extracted_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data Set\n",
    "\n",
    "In this section we will load up the data set and split it into the training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary off all emotions we can measure\n",
    "emotions = {\n",
    "  '01':'neutral',    # file name XX-XX-01 = neutral \n",
    "  '02':'calm',       # file name XX-XX-02 = calm\n",
    "  '03':'happy',      # file name XX-XX-03 = happy\n",
    "  '04':'sad',        # file name XX-XX-04 = sad\n",
    "  '05':'angry',      # file name XX-XX-05 = angry\n",
    "  '06':'fearful',    # file name XX-XX-06 = fearful\n",
    "  '07':'disgust',    # file name XX-XX-07 = disgust\n",
    "  '08':'surprised'   # file name XX-XX-08 = surprised\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we have a dictionary mapping a casted number to an emotion, when going through the data set we are going to load in each entry and then extract it's features. We are then going to split this into training data and test data. We are going to add a parameter for the percentage of data to be in the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the files, extract the features, and split it into the training and test set\n",
    "def load_data(test_size=0.25):\n",
    "    x,y=[],[]\n",
    "    for file in glob.glob(\"../data/Actor_*/*.wav\"):\n",
    "        file_name=os.path.basename(file)\n",
    "        emotion=emotions[file_name.split(\"-\")[2]]\n",
    "        feature=extract_feature(file,  chroma=True, mfcc=True, mel=True, spec_centroid=False, spec_bandwidth=False, spec_contrast=False, roll_off=False)\n",
    "        x.append(feature)\n",
    "        y.append(emotion)\n",
    "    return train_test_split(np.array(x), y, test_size=test_size, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the training and testing data\n",
    "x_train,x_test,y_train,y_test=load_data(0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialising the MLP\n",
    "\n",
    "Here we will initiliase the Mult Level Perception Classifier, with this model there are quite a few parameters we need to consider. So I'm going to go through each one and give a definition of what effect it will have on the model. \n",
    "\n",
    "##### hidden_layer_sizes: tuple (length = n_layers - 2, default=(100,) \n",
    "\n",
    "This is the number of hidden neurones, it should ideally be between the size of the input layer and the size of the output layer. The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer. The number of hidden neurons should be less than twice the size of the input layer.\n",
    "\n",
    "##### activation : {‘identity’, ‘logistic’, ‘tanh’, ‘relu’}, default=’relu’\n",
    "\n",
    "This is the activation function, for the hidden layer \n",
    "* ‘identity’, no-op activation, useful to implement linear bottleneck, returns f(x) = x\n",
    "* ‘logistic’, the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x))\n",
    "* ‘tanh’, the hyperbolic tan function, returns f(x) = tanh(x)\n",
    "* ‘relu’, the rectified linear unit function, returns f(x) = max(0, x)\n",
    "\n",
    "##### solver : {‘lbfgs’, ‘sgd’, ‘adam’}, default=’adam’\n",
    "\n",
    "This is the solver for the weight optimisation \n",
    "* ‘lbfgs’ is an optimizer in the family of quasi-Newton methods\n",
    "* ‘sgd’ refers to stochastic gradient descent\n",
    "* ‘adam’ refers to a stochastic gradient-based optimizer proposed by Kingma, Diederik, and Jimmy Ba \n",
    "\n",
    "The default solver ‘adam’ works pretty well on relatively large datasets (with thousands of training samples or more) in terms of both training time and validation score. For small datasets, however, ‘lbfgs’ can converge faster and perform better.\n",
    "\n",
    "##### alpha : float, default=0.0001\n",
    "\n",
    "So we use L2 Regularization, which involve squaring all of the weights and then summing them together using the alpha value (this alpha value is the L2 penalty value). To my understanding a larger alpha value results in more protection against over fitting.\n",
    "\n",
    "##### batch_size : int, default=’auto’\n",
    "\n",
    "Size of minibatches for stochastic optimizers. If the solver is ‘lbfgs’, the classifier will not use minibatch. When set to “auto”, batch_size=min(200, n_samples)\n",
    "\n",
    "\n",
    "##### learning_rate : {‘constant’, ‘invscaling’, ‘adaptive’}, default=’constant’\n",
    "\n",
    "Learning rate schedule for weight updates.\n",
    "\n",
    "* ‘constant’ is a constant learning rate given by ‘learning_rate_init’.\n",
    "* ‘invscaling’ gradually decreases the learning rate at each time step ‘t’ using an inverse scaling exponent of ‘power_t’. effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
    "* ‘adaptive’ keeps the learning rate constant to ‘learning_rate_init’ as long as training loss keeps decreasing. Each time two consecutive epochs fail to decrease training loss by at least tol, or fail to increase validation score by at least tol if ‘early_stopping’ is on, the current learning rate is divided by 5.\n",
    "Only used when solver='sgd\n",
    "\n",
    "##### max_iter : int, default=200\n",
    "\n",
    "Maximum number of iterations. The solver iterates until convergence (determined by ‘tol’) or this number of iterations. For stochastic solvers (‘sgd’, ‘adam’), note that this determines the number of epochs (how many times each data point will be used), not the number of gradient steps.\n",
    "\n",
    "##### epsilon : float, default=1e-8\n",
    "\n",
    "Value for numerical stability in adam. Only used when solver=’adam’\n",
    "\n",
    "\n",
    "\n",
    "### Adjustments \n",
    "* The max_iter when set to 550 gives the best accuracy.\n",
    "* If alpha is any lower, the accuracy gets reduced.\n",
    "* If alpha is any higher, the accuracy gets increased.\n",
    "* Spectral Centroid reduces the accuracy of our model. \n",
    "* Spectral Contrast Dramatically reduces the accuracy of our model.\n",
    "* Spectral bandwidth reduces the accuracy of our model.\n",
    "* Roll off reduces the accuracy of our model too.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the Multi Layer Perceptron Classifier\n",
    "model=MLPClassifier(alpha=0.005, batch_size=256, epsilon=1e-08, hidden_layer_sizes=(300,), max_iter=550)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model \n",
    "\n",
    "To train the model you use model.fit(self, x, y, batch_size=32, nb_epoch=10, verbose=1, callbacks=[], validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None). We will use the x training data and the y training data. to get an output,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.005, batch_size=256, hidden_layer_sizes=(300,),\n",
       "              max_iter=550)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.65%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy of our model\n",
    "y_pred=model.predict(x_test)\n",
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "Ideally this solution would work and it works relatively well. While you might assume 61% is quite bad, which it is. But the dataset I was working with was not particularly impressive with only 100 pieces of data for each emotion. \n",
    "\n",
    "Something I did notice was the spectral information did result in a lot of overfitting for my model - which sucked a litle bit, but it was a good lesson to learn. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and loading the model \n",
    "\n",
    "Since my model took quite some time to load I am going to use pickle to save the model and use it in other applications - I know this doesn't make a lot of sense for a project with only 60% accuracy but this will be useful for other models i make in the future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "filename = 'emotion-model-reloaded.sav'            \n",
    "pickle.dump(model, open(filename, 'wb'))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 60.65%\n"
     ]
    }
   ],
   "source": [
    "# Loading the model from a file \n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# to recalculate the test \n",
    "y_pred=loaded_model.predict(x_test)\n",
    "accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)\n",
    "# Print the accuracy\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing custom files\n",
    "\n",
    "Now that I've exported it into a separate file I can just load up the information from the pickled file and i have a custom function to get the result from the model. I could probably use this in a  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sad\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open('emotion-model.sav', 'rb'))\n",
    "\n",
    "# A file to load a custom audio file \n",
    "def load_custom_audio_file(filename):\n",
    "    x = []\n",
    "    feature=extract_feature(filename,  chroma=True, mfcc=True, mel=True, spec_centroid=False, spec_bandwidth=False, spec_contrast=False, roll_off=False)\n",
    "    x.append(feature)\n",
    "    return x\n",
    "\n",
    "\n",
    "def predict_for_file(filename):\n",
    "    return model.predict(load_custom_audio_file(filename))[0]\n",
    "\n",
    "print(predict_for_file(\"../data/Actor_01/03-01-03-01-02-02-01.wav\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
